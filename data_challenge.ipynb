{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data challenge - Machine Learning for Geobiology\n",
    "Paulina Körner\n",
    "\n",
    "kaggle user name: Paulina Koerner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Abstract\n",
    "(5 points)\n",
    "- Should be understandable to anyone in the course.\n",
    "- You don’t need to say everything you did, just say what the main idea was and what were one or two takeaways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Introduction\n",
    "(5 points)\n",
    "- A description of the methods you used in the project and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data pre-processing\n",
    "(20 points)\n",
    "- Did you standardize or normalize the data?\n",
    "- Did you use all the features available or selected an optimal subset? If so how did you perform the feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data: \n",
    "- 3000 samples\n",
    "- each row is one sample\n",
    "- 34 columns (mainly chemicals in rock sample)\n",
    "- Label: 0 -> 'Miocene', 1 -> 'Paleogene', 2 -> 'Plio-Quaternary'\n",
    "- Evaluating on F1 metric (not accuracy) – so try to optimize the F1 metric\n",
    "- Look at feature importance \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(757, 33)\n"
     ]
    }
   ],
   "source": [
    "# Import data sets\n",
    "test = pd.read_csv('test.csv')\n",
    "X_test = test.set_index('Id')\n",
    "y_test = test.Id\n",
    "print(X_test.shape)\n",
    "#X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2271, 35)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "print(train.shape)\n",
    "#train.head(10)\n",
    "#print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0     822\n",
       "1    1061\n",
       "2     388\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many samples are from which time period\n",
    "grouped = train.groupby(['Label']).count()\n",
    "grouped.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if dataframe is missing values\n",
    "print(train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n"
     ]
    }
   ],
   "source": [
    "# check if Id's are unique\n",
    "ids = train.Id\n",
    "print(ids.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mean and variance of column values\n",
    "columns = train.columns\n",
    "variability = pd.DataFrame(data=columns, index=None, columns=[\"Column\"])\n",
    "means = train[columns].mean()\n",
    "variability = means.to_frame().reset_index()\n",
    "variability.columns = [\"Columns\", \"Mean\"]\n",
    "variances = train[columns].var()\n",
    "var_df = variances.to_frame().reset_index()\n",
    "var_df.columns = [\"Columns\", \"Variance\"]\n",
    "variability[\"Variance\"] = var_df[\"Variance\"]\n",
    "variability = variability.round({'Mean': 1, 'Variance': 1})\n",
    "\n",
    "#variability.head(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset contains outliers. \n",
    "- The data is not normally distributed.\n",
    "- Can transform features by scaling each feature to a given range unding sklearn.preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = MinMaxScaler(feature_range=(0,1))\\n\\nX = scaler.fit_transform(train.drop(\"Label\", axis=1))\\ntrain_scaled= pd.DataFrame(X, columns=train.drop(\"Label\", axis=1).columns, index=train.index)\\ntrain_scaled[\"Label\"] = train[\"Label\"]\\ntrain_scaled.head()\\n#print(train_scaled[\"Label\"].unique())\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X = scaler.fit_transform(train.drop(\"Label\", axis=1))\n",
    "train_scaled= pd.DataFrame(X, columns=train.drop(\"Label\", axis=1).columns, index=train.index)\n",
    "train_scaled[\"Label\"] = train[\"Label\"]\n",
    "train_scaled.head()\n",
    "#print(train_scaled[\"Label\"].unique())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn = 388\\nlabel0 = train.loc[train[\\'Label\\'] == 0]\\nlabel1 = train.loc[train[\\'Label\\'] == 1]\\nlabel2 = train.loc[train[\\'Label\\'] == 2]\\nprint(\"Shape of label0: \", label0.shape)\\nprint(\"Shape of label1: \", label1.shape)\\nprint(\"Shape of label2: \", label2.shape)\\nprint(\" \")\\n\\nlabel0_sampled = label0.sample(n=n)\\nlabel1_sampled = label1.sample(n=n)\\nprint(\"Shape of label0_sampled: \",label0_sampled.shape)\\nprint(\"Shape of label1_sampled: \",label1_sampled.shape)\\nprint(\" \")\\n\\ntrain_sampled = pd.concat([label2, label0_sampled, label1_sampled])\\nprint(\"Shape of train_sampled: \", train_sampled.shape)\\n\\n# Shuffle rows\\ntrain = train_sampled.sample(frac=1)\\ntrain.head()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Down sampln: select randomly equal number of rows for each label\n",
    "\"\"\"\n",
    "n = 388\n",
    "label0 = train.loc[train['Label'] == 0]\n",
    "label1 = train.loc[train['Label'] == 1]\n",
    "label2 = train.loc[train['Label'] == 2]\n",
    "print(\"Shape of label0: \", label0.shape)\n",
    "print(\"Shape of label1: \", label1.shape)\n",
    "print(\"Shape of label2: \", label2.shape)\n",
    "print(\" \")\n",
    "\n",
    "label0_sampled = label0.sample(n=n)\n",
    "label1_sampled = label1.sample(n=n)\n",
    "print(\"Shape of label0_sampled: \",label0_sampled.shape)\n",
    "print(\"Shape of label1_sampled: \",label1_sampled.shape)\n",
    "print(\" \")\n",
    "\n",
    "train_sampled = pd.concat([label2, label0_sampled, label1_sampled])\n",
    "print(\"Shape of train_sampled: \", train_sampled.shape)\n",
    "\n",
    "# Shuffle rows\n",
    "train = train_sampled.sample(frac=1)\n",
    "train.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outlier detection with isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(random_state=0)\n",
    "pred = clf.fit_predict(train) #identify outliers\n",
    "train_cleaned = train[np.where(pred == 1, True, False)] # remove outliers where 1 represents inliers and -1 represents outliers\n",
    "#train_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned_id = train_cleaned.set_index('Id')\n",
    "#train_cleaned_id = train.set_index('Id') # set index as Id\n",
    "y = train_cleaned_id[\"Label\"] #create y set with Labels\n",
    "x = train_cleaned_id.drop(['Label'], axis = 1) # create x dataset without Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.7 , 14.49,  8.76, ...,  4.69,  8.38,  3.18],\n",
       "       [75.93, 13.01,  0.95, ...,  0.55,  2.13,  6.75],\n",
       "       [58.92, 16.46,  5.87, ...,  2.31,  3.41,  9.66],\n",
       "       ...,\n",
       "       [63.26, 16.36,  5.92, ...,  2.26,  5.62,  3.84],\n",
       "       [68.79, 13.12,  4.76, ...,  2.33,  1.99,  4.15],\n",
       "       [68.23, 16.28,  3.56, ...,  1.54,  4.15,  4.03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest = SelectKBest(k=33)\n",
    "kbest.fit_transform(x, y)\n",
    "#X_test = kbest.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sm/Yb': 320.93386481124253, '(Sm/Yb)N': 320.3973272109341, '(La/Yb)N': 293.9616367013765, 'La/Yb': 293.8846357215445, 'La': 239.2664151201812, 'LaN': 238.7155781442083, 'CeN': 232.67726898207405, 'Ce': 232.61695526214538, 'Nb/Yb': 216.01414465516834, 'Nb': 155.70371857217455, 'Sm': 120.90867896360325, 'SmN': 120.71950891463344, 'Yb': 107.67378362745029, 'YbN': 107.67234876706569, 'Ti': 103.51667969827291, 'TiO2(LOI free)': 102.09686869162626, 'La/Sm': 93.18806169095353, 'SiO2(LOI free)': 61.23445800650728, 'SiO2': 59.59308795931548, 'MgO(LOI free)': 59.5930789074193, 'CaO': 51.639861061617125, 'CaO(LOI free)': 51.15636139059611, 'Rb/Sm': 40.39054566450408, 'Nb/La': 36.875479011276816, 'Fe2O3tot': 36.2093895464009, 'Fe2O3(LOI free)': 36.182567960372545, 'Nb/Rb': 22.677306885450857, 'La/Nb': 21.310459270148254, 'Na2O(LOI free)': 21.050119417519003, 'Rb': 18.834137633201408, 'Al2O3(LOI free)': 15.59498412986893, 'Al2O3': 14.726758652649913, 'Total': 10.222824468988215}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = kbest.scores_\n",
    "features = kbest.feature_names_in_\n",
    "feature_scores = {}\n",
    "\n",
    "for i in range(len(scores)):\n",
    "  feature_scores[features[i]] = scores[i]\n",
    "\n",
    "feature_scores = sorted(feature_scores.items(), key=lambda x:x[1], reverse=True)\n",
    "scores_sorted = dict(feature_scores)\n",
    "print(scores_sorted)\n",
    "\n",
    "#dict_scores = feature_scores\n",
    "dict_scores = scores_sorted\n",
    "x_plot = np.arange(len(dict_scores))\n",
    "y_plot = dict_scores.values()\n",
    "plt.bar(x_plot, y_plot)\n",
    "plt.xticks(x_plot + 0.5, dict_scores.keys(), rotation='vertical')\n",
    "plt.xlabel(\"features\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no clear elbow visible so I won't to feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling\n",
    "(40 points)\n",
    "- What are the model assumptions?\n",
    "- Is there any evidence to support them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# cross validation to select the optimal number of neighbors the KNN classifier should use\\n# Cross validation fits the model on a subset of the training data and predicts labels on the remaining training samples\\n# By repeating this operation with different k parameters, I can estimate which value fits our problem the best.\\n\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.neighbors import KNeighborsClassifier\\nimport matplotlib.pyplot as plt\\n\\nk_range = list(range(1, 31, 1))\\nparam_grid = dict(n_neighbors=k_range)\\n\\ngrid = GridSearchCV(KNeighborsClassifier(), param_grid)\\ngrid.fit(X_train, y_train)\\n\\nmean_test_scores = grid.cv_results_[\\'mean_test_score\\']\\nbest_estimator = grid.best_estimator_\\naccuracy = grid.best_score_ *100\\n\\nplt.plot(k_range, mean_test_scores, \"bo\")\\n#plt.axvspan(2.5, 3.5, color=\\'green\\', alpha=0.5)\\nplt.title(\"Mean test score for each parameter\")\\nplt.xlabel(\"parameters k\")\\nplt.ylabel(\"mean test score\")\\nplt.show()\\nprint(\"Mean test scores for parameters k: \", mean_test_scores)\\nprint(best_estimator)\\nprint(\"Accuracy of best parameter: \",accuracy)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# cross validation to select the optimal number of neighbors the KNN classifier should use\n",
    "# Cross validation fits the model on a subset of the training data and predicts labels on the remaining training samples\n",
    "# By repeating this operation with different k parameters, I can estimate which value fits our problem the best.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_range = list(range(1, 31, 1))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "mean_test_scores = grid.cv_results_['mean_test_score']\n",
    "best_estimator = grid.best_estimator_\n",
    "accuracy = grid.best_score_ *100\n",
    "\n",
    "plt.plot(k_range, mean_test_scores, \"bo\")\n",
    "#plt.axvspan(2.5, 3.5, color='green', alpha=0.5)\n",
    "plt.title(\"Mean test score for each parameter\")\n",
    "plt.xlabel(\"parameters k\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()\n",
    "print(\"Mean test scores for parameters k: \", mean_test_scores)\n",
    "print(best_estimator)\n",
    "print(\"Accuracy of best parameter: \",accuracy)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nknn = KNeighborsClassifier(n_neighbors=3)\\nknn.fit(X_train, y_train)\\n\\n# Accuracy\\nfrom sklearn.metrics import accuracy_score\\n\\ny_predicted = knn.predict(X_val)\\naccuracy_prediction = accuracy_score(y_val, y_predicted)\\nprint(\"Test accuracy: \", accuracy_prediction)\\n\\n# F1 score\\nf1 = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=\\'weighted\\')\\nprint(\"F1 score: \", f1)\\nf1_label = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=None)\\nprint(\"F1 for each label: \", f1_label)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predicted = knn.predict(X_val)\n",
    "accuracy_prediction = accuracy_score(y_val, y_predicted)\n",
    "print(\"Test accuracy: \", accuracy_prediction)\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average='weighted')\n",
    "print(\"F1 score: \", f1)\n",
    "f1_label = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=None)\n",
    "print(\"F1 for each label: \", f1_label)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.tree import DecisionTreeClassifier\\nimport matplotlib.pyplot as plt\\n\\ndepth_range = list(range(2, 9))\\ntree_param = dict(max_depth=depth_range)\\n\\ngrid_dtc = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_param)\\ngrid_dtc.fit(X_train, y_train)\\n\\nmean_test_scores_dtc = grid_dtc.cv_results_[\\'mean_test_score\\']\\nbest_estimator_dtc = grid_dtc.best_estimator_\\naccuracy_dtc = grid_dtc.best_score_ *100\\n\\nplt.plot(depth_range, mean_test_scores_dtc, \"yo\")\\nplt.axvspan(7.9, 8.1, color=\\'green\\', alpha=0.5)\\nplt.title(\"Mean test score for each parameter\")\\nplt.xlabel(\"parameters k\")\\nplt.ylabel(\"mean test score\")\\nplt.show()\\nprint(\"Mean test scores for parameters k: \", mean_test_scores_dtc)\\nprint(best_estimator_dtc)\\nprint(\"Accuracy of best parameters 3: \",accuracy_dtc)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "depth_range = list(range(2, 9))\n",
    "tree_param = dict(max_depth=depth_range)\n",
    "\n",
    "grid_dtc = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_param)\n",
    "grid_dtc.fit(X_train, y_train)\n",
    "\n",
    "mean_test_scores_dtc = grid_dtc.cv_results_['mean_test_score']\n",
    "best_estimator_dtc = grid_dtc.best_estimator_\n",
    "accuracy_dtc = grid_dtc.best_score_ *100\n",
    "\n",
    "plt.plot(depth_range, mean_test_scores_dtc, \"yo\")\n",
    "plt.axvspan(7.9, 8.1, color='green', alpha=0.5)\n",
    "plt.title(\"Mean test score for each parameter\")\n",
    "plt.xlabel(\"parameters k\")\n",
    "plt.ylabel(\"mean test score\")\n",
    "plt.show()\n",
    "print(\"Mean test scores for parameters k: \", mean_test_scores_dtc)\n",
    "print(best_estimator_dtc)\n",
    "print(\"Accuracy of best parameters 3: \",accuracy_dtc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndtc = DecisionTreeClassifier(max_depth=8, random_state=42)\\ndtc.fit(X_train, y_train)\\n\\ny_predicted = dtc.predict(X_val)\\naccuracy_prediction = accuracy_score(y_val, y_predicted)\\nprint(\"Test accuracy: \", accuracy_prediction)\\n\\n# F1 score\\nf1 = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=\\'weighted\\')\\nprint(\"F1 score: \", f1)\\nf1_label = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=None)\\nprint(\"F1 for each label: \", f1_label)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dtc = DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = dtc.predict(X_val)\n",
    "accuracy_prediction = accuracy_score(y_val, y_predicted)\n",
    "print(\"Test accuracy: \", accuracy_prediction)\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average='weighted')\n",
    "print(\"F1 score: \", f1)\n",
    "f1_label = f1_score(y_true=y_val, y_pred=y_predicted,labels=[0,1,2], average=None)\n",
    "print(\"F1 for each label: \", f1_label)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  0.7855421686746988\n",
      "F1 score:  0.7833599729986693\n",
      "F1 for each label:  [0.76582278 0.82352941 0.69811321]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size = 0.20)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 100) \n",
    "#rfc = RandomForestClassifier(n_estimators = 100, criterion=\"entropy\") \n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "feature_imp = pd.Series(rfc.feature_importances_, index = x.columns).sort_values(ascending = False)\n",
    "#print(feature_imp)\n",
    "\n",
    "val_pred = rfc.predict(X_val)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of the model: \", metrics.accuracy_score(y_val, val_pred))\n",
    "# F1 score\n",
    "f1 = f1_score(y_true=y_val, y_pred=val_pred,labels=[0,1,2], average='weighted')\n",
    "print(\"F1 score: \", f1)\n",
    "f1_label = f1_score(y_true=y_val, y_pred=val_pred,labels=[0,1,2], average=None)\n",
    "print(\"F1 for each label: \", f1_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_df = pd.DataFrame(y_pred)\n",
    "y_test_pred_df.rename(columns = {0:'Label'}, inplace= True)\n",
    "\n",
    "output = pd.concat([y_test_pred_df, y_test], axis=1)\n",
    "pred_RandomForest = output.to_csv('pred_RandomForest.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearch & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "depth_range = list(range(17, 19))\n",
    "#depth_range = list(range(15, 25))\n",
    "#tree_param = dict(max_depth=depth_range, n_estimators=[800, 900, 1000], criterion=[\"entropy\"])\n",
    "tree_param = dict(max_depth=depth_range, n_estimators=[1000], criterion=[\"entropy\"])\n",
    "\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(random_state=42), tree_param, cv=10)\n",
    "#grid_dtc = GridSearchCV(RandomForestClassifier(random_state=0), tree_param)\n",
    "grid_rfc.fit(x, y)\n",
    "\n",
    "mean_test_scores_rfc = grid_rfc.cv_results_['mean_test_score']\n",
    "best_estimator_rfc = grid_rfc.best_estimator_\n",
    "accuracy_rfc = grid_rfc.best_score_ *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test scores:  [0.80421544 0.80373467 0.80324926 0.8066309  0.80663322 0.80760173\n",
      " 0.80759244 0.80614084 0.80614084 0.80711167 0.80710935 0.80903939\n",
      " 0.80614548 0.80662858 0.8085563  0.80615013 0.80807553 0.80711631\n",
      " 0.8066309  0.80614548 0.80662858 0.80663322 0.80663322 0.80662858\n",
      " 0.80518627 0.8066309  0.80614548 0.8047055  0.8066309  0.80566472]\n",
      "Best estimator:  RandomForestClassifier(criterion='entropy', max_depth=18, n_estimators=1000,\n",
      "                       random_state=42)\n",
      "Accuracy:  80.90393905611297\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test scores: \", mean_test_scores_rfc)\n",
    "print(\"Best estimator: \", grid_rfc.best_estimator_)\n",
    "print(\"Accuracy: \", accuracy_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best so far max: 80.90393905611297\n",
    "\n",
    "RandomForestClassifier(criterion='entropy', max_depth=18, n_estimators=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "rfc = best_estimator_rfc\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.rename(columns = {0:'Label'}, inplace= True)\n",
    "\n",
    "result = pd.concat([predictions_df, y_test], axis=1)\n",
    "pred_GSRandomForest = result.to_csv('pred_GSRandomForest.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0508793\ttotal: 92.3ms\tremaining: 4.52s\n",
      "1:\tlearn: 1.0096832\ttotal: 104ms\tremaining: 2.5s\n",
      "2:\tlearn: 0.9751216\ttotal: 120ms\tremaining: 1.88s\n",
      "3:\tlearn: 0.9434463\ttotal: 133ms\tremaining: 1.53s\n",
      "4:\tlearn: 0.9168675\ttotal: 146ms\tremaining: 1.31s\n",
      "5:\tlearn: 0.8920098\ttotal: 156ms\tremaining: 1.14s\n",
      "6:\tlearn: 0.8702112\ttotal: 175ms\tremaining: 1.08s\n",
      "7:\tlearn: 0.8512157\ttotal: 186ms\tremaining: 975ms\n",
      "8:\tlearn: 0.8334094\ttotal: 200ms\tremaining: 909ms\n",
      "9:\tlearn: 0.8157952\ttotal: 218ms\tremaining: 873ms\n",
      "10:\tlearn: 0.8021812\ttotal: 237ms\tremaining: 839ms\n",
      "11:\tlearn: 0.7870681\ttotal: 262ms\tremaining: 831ms\n",
      "12:\tlearn: 0.7757612\ttotal: 277ms\tremaining: 789ms\n",
      "13:\tlearn: 0.7654357\ttotal: 286ms\tremaining: 736ms\n",
      "14:\tlearn: 0.7544893\ttotal: 301ms\tremaining: 703ms\n",
      "15:\tlearn: 0.7448085\ttotal: 341ms\tremaining: 726ms\n",
      "16:\tlearn: 0.7350152\ttotal: 352ms\tremaining: 684ms\n",
      "17:\tlearn: 0.7270566\ttotal: 368ms\tremaining: 655ms\n",
      "18:\tlearn: 0.7176274\ttotal: 380ms\tremaining: 621ms\n",
      "19:\tlearn: 0.7097911\ttotal: 393ms\tremaining: 589ms\n",
      "20:\tlearn: 0.7003330\ttotal: 406ms\tremaining: 561ms\n",
      "21:\tlearn: 0.6942508\ttotal: 422ms\tremaining: 538ms\n",
      "22:\tlearn: 0.6885919\ttotal: 431ms\tremaining: 506ms\n",
      "23:\tlearn: 0.6828725\ttotal: 444ms\tremaining: 481ms\n",
      "24:\tlearn: 0.6777266\ttotal: 465ms\tremaining: 465ms\n",
      "25:\tlearn: 0.6719189\ttotal: 478ms\tremaining: 441ms\n",
      "26:\tlearn: 0.6671216\ttotal: 489ms\tremaining: 416ms\n",
      "27:\tlearn: 0.6620479\ttotal: 498ms\tremaining: 391ms\n",
      "28:\tlearn: 0.6576928\ttotal: 518ms\tremaining: 375ms\n",
      "29:\tlearn: 0.6534527\ttotal: 555ms\tremaining: 370ms\n",
      "30:\tlearn: 0.6497627\ttotal: 571ms\tremaining: 350ms\n",
      "31:\tlearn: 0.6449138\ttotal: 581ms\tremaining: 327ms\n",
      "32:\tlearn: 0.6411750\ttotal: 593ms\tremaining: 305ms\n",
      "33:\tlearn: 0.6356864\ttotal: 612ms\tremaining: 288ms\n",
      "34:\tlearn: 0.6313941\ttotal: 625ms\tremaining: 268ms\n",
      "35:\tlearn: 0.6299079\ttotal: 636ms\tremaining: 247ms\n",
      "36:\tlearn: 0.6255779\ttotal: 650ms\tremaining: 228ms\n",
      "37:\tlearn: 0.6222876\ttotal: 667ms\tremaining: 211ms\n",
      "38:\tlearn: 0.6187343\ttotal: 675ms\tremaining: 190ms\n",
      "39:\tlearn: 0.6138710\ttotal: 687ms\tremaining: 172ms\n",
      "40:\tlearn: 0.6095538\ttotal: 706ms\tremaining: 155ms\n",
      "41:\tlearn: 0.6059908\ttotal: 730ms\tremaining: 139ms\n",
      "42:\tlearn: 0.6040089\ttotal: 751ms\tremaining: 122ms\n",
      "43:\tlearn: 0.5994405\ttotal: 764ms\tremaining: 104ms\n",
      "44:\tlearn: 0.5953172\ttotal: 776ms\tremaining: 86.2ms\n",
      "45:\tlearn: 0.5921374\ttotal: 787ms\tremaining: 68.4ms\n",
      "46:\tlearn: 0.5894388\ttotal: 805ms\tremaining: 51.4ms\n",
      "47:\tlearn: 0.5867495\ttotal: 815ms\tremaining: 33.9ms\n",
      "48:\tlearn: 0.5842354\ttotal: 826ms\tremaining: 16.9ms\n",
      "49:\tlearn: 0.5810839\ttotal: 840ms\tremaining: 0us\n",
      "Accuracy of the model:  0.7036144578313253\n",
      "F1 score:  0.7001723707031065\n",
      "F1 for each label:  [0.66666667 0.74698795 0.64220183]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size = 0.20)\n",
    "\n",
    "model = CatBoostClassifier(iterations=50,random_seed=42,learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# using metrics module for accuracy calculation\n",
    "print(\"Accuracy of the model: \", metrics.accuracy_score(y_val, preds))\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_true=y_val, y_pred=preds,labels=[0,1,2], average='weighted')\n",
    "print(\"F1 score: \", f1)\n",
    "f1_label = f1_score(y_true=y_val, y_pred=preds,labels=[0,1,2], average=None)\n",
    "print(\"F1 for each label: \", f1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds)\n",
    "preds_df.rename(columns = {0:'Label'}, inplace= True)\n",
    "\n",
    "result = pd.concat([preds_df, y_test], axis=1)\n",
    "pred_CatBoost = result.to_csv('pred_CatBoost.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndepth_range = list(range(2, 9))\\n#tree_param = dict(max_depth=depth_range, n_estimators=[100, 800, 1000], criterion=[\"gini\", \"entropy\"])\\ncat_param = dict(max_depth=depth_range, n_estimators=[10, 100, 1000], learning_rate=[0.01, 0.1, 1])\\n#only one of the parameters iterations, n_estimators, num_boost_round, num_trees should be initialized.\\n\\n\\ngrid_cbc = GridSearchCV(CatBoostClassifier(random_seed=42), cat_param, cv=5)\\n#grid_dtc = GridSearchCV(RandomForestClassifier(random_state=0), tree_param)\\ngrid_cbc.fit(X_new, y)\\n\\nmean_test_scores_cbc = grid_cbc.cv_results_[\\'mean_test_score\\']\\nbest_estimator_cbc = grid_cbc.best_estimator_\\naccuracy_cbc = grid_cbc.best_score_ *100\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "depth_range = list(range(2, 9))\n",
    "#tree_param = dict(max_depth=depth_range, n_estimators=[100, 800, 1000], criterion=[\"gini\", \"entropy\"])\n",
    "cat_param = dict(max_depth=depth_range, n_estimators=[10, 100, 1000], learning_rate=[0.01, 0.1, 1])\n",
    "#only one of the parameters iterations, n_estimators, num_boost_round, num_trees should be initialized.\n",
    "\n",
    "\n",
    "grid_cbc = GridSearchCV(CatBoostClassifier(random_seed=42), cat_param, cv=5)\n",
    "#grid_dtc = GridSearchCV(RandomForestClassifier(random_state=0), tree_param)\n",
    "grid_cbc.fit(X_new, y)\n",
    "\n",
    "mean_test_scores_cbc = grid_cbc.cv_results_['mean_test_score']\n",
    "best_estimator_cbc = grid_cbc.best_estimator_\n",
    "accuracy_cbc = grid_cbc.best_score_ *100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# using metrics module for accuracy calculation\\nprint(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_val, y_pred))\\n\\n# F1 score\\nf1 = f1_score(y_true=y_val, y_pred=y_pred,labels=[0,1,2], average=\\'weighted\\')\\nprint(\"F1 score: \", f1)\\nf1_label = f1_score(y_true=y_val, y_pred=y_pred,labels=[0,1,2], average=None)\\nprint(\"F1 for each label: \", f1_label)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_true=y_val, y_pred=y_pred,labels=[0,1,2], average='weighted')\n",
    "print(\"F1 score: \", f1)\n",
    "f1_label = f1_score(y_true=y_val, y_pred=y_pred,labels=[0,1,2], average=None)\n",
    "print(\"F1 for each label: \", f1_label)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Validation\n",
    "(20 points)\n",
    "- Did you compare your model to a simpler baseline model?\n",
    "- Did you perform an extensive evaluation of your model? (e.g. k-fold cross-validation) \n",
    "- Does the accuracy of your model drop when it is evaluated on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Limitations\n",
    "(5 points)\n",
    "- What are the limitations of your approach?\n",
    "- Give some examples of possible extensions or ways to address these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Conclusions\n",
    "(5 points)\n",
    "- State the results achieved in relation to the problem described in the introduction. \n",
    "- Include the main takeaways from your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
